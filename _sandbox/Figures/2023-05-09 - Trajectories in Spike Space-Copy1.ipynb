{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a49507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e2872e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from copy import deepcopy\n",
    "from matplotlib.cm import get_cmap, ScalarMappable\n",
    "from matplotlib import colors\n",
    "from matplotlib.colors import Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from spynal.spikes import density\n",
    "import sys\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "plt.style.use('../../sci_style.py')\n",
    "\n",
    "sys.path.append('../..')\n",
    "from data_utils import get_data_class, load_session_data, load_window_from_chunks\n",
    "\n",
    "sys.path.append('../../../DeLASE')\n",
    "from utils import numpy_torch_conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc11ab6",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac9db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, n_components=None, use_torch=False, device='cpu', dtype='torch.DoubleTensor'):\n",
    "        self.n_components = n_components\n",
    "        self.use_torch = use_torch\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        \n",
    "    def compute_multidim_mean(self, data):\n",
    "        return data.mean(axis=tuple(np.arange(0, len(data.shape)-1)))\n",
    "    \n",
    "    def fit(self, data):\n",
    "        data = numpy_torch_conversion(data, self.use_torch, self.device, self.dtype)   \n",
    "        data_centered = data - self.compute_multidim_mean(data)\n",
    "        if self.use_torch:\n",
    "            U, S, Vh = torch.linalg.svd(data_centered, full_matrices=False)\n",
    "            self.U = U\n",
    "            self.S = S\n",
    "            self.V = Vh.T\n",
    "\n",
    "        else:\n",
    "            U, S, Vh = np.linalg.svd(data_centered, full_matrices=False)\n",
    "            self.U = U\n",
    "            self.S = S\n",
    "            self.V = Vh.T\n",
    "        \n",
    "        self.explained_variance_ = ((S**2)/(data.shape[0] - 1))[:self.n_components]\n",
    "    \n",
    "    def transform(self, data):\n",
    "        data = numpy_torch_conversion(data, self.use_torch, self.device, self.dtype)\n",
    "        data_centered = data - self.compute_multidim_mean(data)\n",
    "        return (data_centered) @ self.V[:, :self.n_components]\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "def get_bins(spike_mat, bin_size):\n",
    "    \"\"\"\n",
    "    Helper function for get_up_down_raw() function. \n",
    "\n",
    "    Calculate number of bins based on bin_size, remove extra\n",
    "    data at end, and return spikes/bin count array.\n",
    "    \"\"\"\n",
    "    trial_length = spike_mat.shape[1]\n",
    "    n_bins = np.floor(trial_length / bin_size)\n",
    "\n",
    "    cut_ind = int(n_bins*bin_size)\n",
    "\n",
    "    clipped_spike_mat = spike_mat[:,:cut_ind]\n",
    "    \n",
    "    return sum_bins(clipped_spike_mat, n_bins)\n",
    "    \n",
    "def sum_bins(spike_mat, n_bins):\n",
    "    \"\"\"\n",
    "    Helper function for get_bins() function. \n",
    "\n",
    "    Break apart spike_mat (0/1 spike array) into n_bins and\n",
    "    return (n_bin,) length array containing spike counts per bin.\n",
    "    \"\"\"\n",
    "    split = np.hsplit(spike_mat, n_bins)\n",
    "    join = np.stack(split)\n",
    "    \n",
    "    return join.sum(axis=(1,2))\n",
    "\n",
    "def get_up_down_raw(area_spike_dict, bin_size=200, Fs=1000, thresh=0.1, \n",
    "                trange=None, smooth=True):\n",
    "    \"\"\"\n",
    "    For each spike array in area_spike_dict, get 0/1 Up/Down array at bin_size \n",
    "    resolution.\n",
    "    Optional smooth: fill in 101 case with 111\n",
    "    Returns dictionary with Up/Down raw array per region.\n",
    "    \"\"\"\n",
    "    \n",
    "    areas = list(area_spike_dict.keys())\n",
    "\n",
    "    data_length = area_spike_dict[areas[0]].shape[1]\n",
    "    # n_bins = int(np.floor(data_length / bin_size))\n",
    "    \n",
    "    if trange is None:\n",
    "        trange = np.arange(data_length)\n",
    "    \n",
    "    binned_up_down_dict = {}\n",
    "    \n",
    "    for a, spikes in area_spike_dict.items():\n",
    "        if a == '7b':\n",
    "            thresh = 0.2\n",
    "        else:\n",
    "            thresh = thresh\n",
    "\n",
    "        binned = get_bins(spikes, bin_size)\n",
    "        binned_up_down_dict[a] = (((binned / area_spike_dict[a].shape[0])\\\n",
    "                        * (200/bin_size)) > thresh).astype(float)\n",
    "\n",
    "    if smooth:\n",
    "        for a, binned in binned_up_down_dict.items():\n",
    "            for n in range(binned.size):\n",
    "                if n == 0 or n == binned.size-1:\n",
    "                    pass\n",
    "                else:\n",
    "                    if binned[n-1] == 1 and binned[n+1] == 1:\n",
    "                        binned[n] = 1\n",
    "\n",
    "    up_down_dict = {k: np.repeat(v, bin_size) for k,v\\\n",
    "                    in binned_up_down_dict.items()}\n",
    "    \n",
    "    return up_down_dict\n",
    "\n",
    "# NOTE - some shoddy conditionals for handling boundary issues\n",
    "# WATCH FOR ISSUES\n",
    "def get_up_edges(up_down_array):\n",
    "    \"\"\"\n",
    "    Get indices for starts/ends of sequence of ones in up_down_array.\n",
    "    Check / fix common errors due to boundary issues.\n",
    "    \"\"\"\n",
    "    starts = np.where(np.diff(up_down_array) == 1)[0] + 1\n",
    "    ends = np.where(np.diff(up_down_array) == -1)[0] + 1\n",
    "    \n",
    "    if ends[0] <= starts[0]:\n",
    "        ends = ends[1:]\n",
    "        starts = starts[:-1]\n",
    "        \n",
    "    if ends.size != starts.size:\n",
    "        min_size = min(ends.size, starts.size)\n",
    "        starts = starts[:min_size]\n",
    "        ends = ends[:min_size]\n",
    "    \n",
    "    return starts, ends\n",
    "\n",
    "\n",
    "\n",
    "def trim_up_down_array(expanded_up, area_spike_seg):\n",
    "    \"\"\"\n",
    "    Remove trailing Up/Down labels based on 0-spike counts at \n",
    "    beginning/end of Up segement in Up/Down array.\n",
    "    \"\"\"\n",
    "    trimmed_up = np.zeros(expanded_up.size)\n",
    "    up_starts, up_ends = get_up_edges(expanded_up)\n",
    "    # need to handle case where these aren't equal?\n",
    "    for i in range(up_starts.size):\n",
    "        s = up_starts[i]\n",
    "        e = up_ends[i]\n",
    "        up_seg = area_spike_seg[:,s:e]\n",
    "        \n",
    "        nonzeros = np.nonzero(up_seg.sum(0))[0]\n",
    "        new_s = s + nonzeros[0]\n",
    "        new_e = s + nonzeros[-1]\n",
    "        \n",
    "        trimmed_up[new_s:new_e] = 1\n",
    "        \n",
    "    return trimmed_up\n",
    "\n",
    "def trim_up_down(expand_dict, area_spikes_dict):\n",
    "    \"\"\"\n",
    "    Apply trim_up_down_array to each region in dictionary.\n",
    "    \"\"\"\n",
    "    trimmed_dict = {}\n",
    "    for a in expand_dict.keys():\n",
    "        expand_up = expand_dict[a]\n",
    "        spikes_seg = area_spikes_dict[a]\n",
    "        \n",
    "        trimmed_dict[a] = trim_up_down_array(expand_up, spikes_seg)\n",
    "        \n",
    "    return trimmed_dict\n",
    "\n",
    "def get_up_down(area_spike_dict, bin_size=200):\n",
    "    \"\"\"\n",
    "    Apply full Up/Down processing to each region in area_spike_dict.\n",
    "    Returns new dictionary w/ full/processed Up/Down array per region.\n",
    "    \"\"\"\n",
    "    raw_up_down_dict = get_up_down_raw(area_spike_dict, bin_size=bin_size)\n",
    "    up_down_dict = trim_up_down(raw_up_down_dict, area_spike_dict)\n",
    "\n",
    "    return up_down_dict\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    '''Make axes of 3D plot have equal scale so that spheres appear as spheres,\n",
    "    cubes as cubes, etc..  This is one possible solution to Matplotlib's\n",
    "    ax.set_aspect('equal') and ax.axis('equal') not working for 3D.\n",
    "\n",
    "    Input\n",
    "      ax: a matplotlib axis, e.g., as output from plt.gca().\n",
    "    '''\n",
    "\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    # The plot bounding box is a sphere in the sense of the infinity\n",
    "    # norm, hence I call half the max range the plot radius.\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff57ca5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32d94ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session = 'MrJones-Anesthesia-20160109-01'\n",
    "session = 'Mary-Anesthesia-20160912-02'\n",
    "results_dir = '/scratch2/weka/millerlab/eisenaj/ChaoticConsciousness/session_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "320fde4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_dir = '/scratch2/weka/millerlab/eisenaj/datasets/anesthesia/mat'\n",
    "data_class = get_data_class(session, all_data_dir)\n",
    "\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "# variables = ['electrodeInfo', 'lfp', 'lfpSchema', 'sessionInfo', 'trialInfo', 'unitInfo']\n",
    "# session_vars, T, N, dt = load_session_data(session, all_data_dir, variables, data_class=data_class, verbose=False)\n",
    "# electrode_info, lfp, lfp_schema, session_info, trial_info, unit_info = session_vars['electrodeInfo'], session_vars['lfp'], session_vars['lfpSchema'], session_vars['sessionInfo'], session_vars['trialInfo'], session_vars['unitInfo']\n",
    "\n",
    "variables = ['electrodeInfo', 'lfpSchema', 'sessionInfo', 'spikeTimes', 'trialInfo', 'unitInfo']\n",
    "session_vars, T, N, dt = load_session_data(session, all_data_dir, variables, data_class=data_class, verbose=False)\n",
    "electrode_info, lfp_schema, session_info, spike_times, trial_info, unit_info = session_vars['electrodeInfo'], session_vars['lfpSchema'], session_vars['sessionInfo'], session_vars['spikeTimes'], session_vars['trialInfo'], session_vars['unitInfo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27a62943",
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes_open = session_info['eyesOpen'][-1] if isinstance(session_info['eyesOpen'], np.ndarray) else session_info['eyesOpen']\n",
    "eyes_close = session_info['eyesClose'][-1] if isinstance(session_info['eyesClose'], np.ndarray) else session_info['eyesClose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e585ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_times = dict( \n",
    "        wake=(0, session_info['drugStart'][0]),\n",
    "        induction=(session_info['drugStart'][0], eyes_close),\n",
    "        anesthesia=(eyes_close, session_info['drugEnd'][1]),\n",
    "        recovery=(session_info['drugEnd'][1], T*dt)\n",
    ")\n",
    "sections = list(section_times.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b8d08cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_on = trial_info['cpt_toneOn'][~np.isnan(trial_info['cpt_toneOn'])]\n",
    "tone_off = trial_info['cpt_toneOff'][~np.isnan(trial_info['cpt_toneOff'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1158252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area_spike_dict = {}\n",
    "# for area in np.hstack([session_info['areas']]):\n",
    "#     print(area)\n",
    "#     if area == 'all':\n",
    "#         unit_inds = np.arange(len(unit_info['area']))\n",
    "#     else:\n",
    "#         unit_inds = np.where(unit_info['area'] == area)[0]\n",
    "#     area_spike_dict[area] = np.zeros((len(unit_inds), T))\n",
    "#     for i, ind in enumerate(unit_inds):\n",
    "#         unit_spike_times = spike_times[ind]\n",
    "#         for t in unit_spike_times:\n",
    "#             area_spike_dict[area][i, int(t/dt)] = 1\n",
    "# up_down_dict = get_up_down(area_spike_dict, bin_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c4ac4f",
   "metadata": {},
   "source": [
    "# Load Rate Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1bc5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 0.1 # s\n",
    "step = 0.001 # s\n",
    "dt_rate = step\n",
    "\n",
    "# area = 'CPB'\n",
    "# if area == 'all':\n",
    "#     unit_indices = np.arange(len(unit_info['area']))\n",
    "# else:\n",
    "#     unit_indices = np.where(unit_info['area'] == area)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d96d2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = f\"/scratch2/weka/millerlab/eisenaj/datasets/anesthesia/mat/propofolPuffTone/{session}_rates_width_{width}_step_{step}_chunked_20s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9bcd47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = pd.read_pickle(os.path.join(dir_, \"directory\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21df0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_colors = {\n",
    "    'vlPFC': 'C0',\n",
    "    'FEF': 'skyblue',\n",
    "    '7b': 'slategray',\n",
    "    'CPB': 'lightsteelblue', \n",
    "    'all': 'purple'\n",
    "}\n",
    "# area_colors = {\n",
    "#     'vlPFC': palette2[0], \n",
    "#     'FEF': palette2[2],\n",
    "#     '7b': palette2[3],\n",
    "#     'CPB': palette2[4]\n",
    "# }\n",
    "area_labels = {\n",
    "    'CPB': 'STG',\n",
    "    '7b': 'PPC',\n",
    "    'FEF': 'FEF',\n",
    "    'vlPFC': 'PFC',\n",
    "    'all': 'ALL'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4c9366ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_wake = 500 # s\n",
    "start_anesthesia = session_info['drugStart'][1] - 15 # s\n",
    "window = 15 # s\n",
    "\n",
    "three_dim = False\n",
    "density_plot = False\n",
    "scatter = True\n",
    "start_ind = 0\n",
    "# end_ind = window_lfp if mode == 'lfp' else window_rate\n",
    "end_ind = 10000\n",
    "cbar_step = 2000\n",
    "norm = colors.Normalize(vmin=start_ind, vmax=end_ind)\n",
    "cmap = plt.cm.get_cmap('RdYlBu_r')\n",
    "\n",
    "shared_basis = True\n",
    "standardize = True\n",
    "\n",
    "embed_type = 'PCA'\n",
    "\n",
    "\n",
    "# # window_lfp = int(window/dt)\n",
    "# # window_rate = int(window/dt_rate)\n",
    "# window_lfp = 15000\n",
    "# window_rate = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b521cc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "AREA = vlPFC\n",
      "----------------------------------------\n",
      "loading data...\n",
      "performing PCA...\n",
      "generating plot ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0bc087eadc4e19b4fee55b6231507e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "AREA = FEF\n",
      "----------------------------------------\n",
      "loading data...\n",
      "performing PCA...\n",
      "generating plot ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8038d8a12edd4043900a7a3f4ca282db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "AREA = 7b\n",
      "----------------------------------------\n",
      "loading data...\n",
      "performing PCA...\n",
      "generating plot ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e625945b4e854fe4be64fc09c91de461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "AREA = CPB\n",
      "----------------------------------------\n",
      "loading data...\n",
      "performing PCA...\n",
      "generating plot ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52ad9587dcd42baa3f60b14102fdb8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subtitle_fontsize = 18\n",
    "subsuptitle_fontsize = 20\n",
    "ylabel_fontsize = 16\n",
    "xlabel_fontsize = 16\n",
    "tick_fontsize = 14\n",
    "\n",
    "fig = plt.figure(layout='constrained', figsize=(15, 7))\n",
    "subfigs = fig.subfigures(2, 2, wspace=0.07, hspace=0.07)\n",
    "\n",
    "for i, area in enumerate(['vlPFC', 'FEF', '7b', 'CPB']):\n",
    "    subfig = subfigs[int(i/2)][i % 2]\n",
    "    print(\"-\"*40)\n",
    "    print(f\"AREA = {area}\")\n",
    "    print(\"-\"*40)\n",
    "    print(\"loading data...\")\n",
    "    if area == 'all':\n",
    "        unit_indices = np.arange(len(unit_info['area']))\n",
    "    else:\n",
    "        unit_indices = np.where(unit_info['area'] == area)[0]\n",
    "        \n",
    "    signal_wake = load_window_from_chunks(start_wake, start_wake + window, directory, unit_indices)\n",
    "    signal_anesthesia = load_window_from_chunks(start_anesthesia, start_anesthesia + window, directory, unit_indices)\n",
    "    \n",
    "    if embed_type == 'PCA':\n",
    "        manifold_embed = lambda n_comp: PCA(n_components=n_comp, use_torch=True, device='cuda')\n",
    "    else: # embed_type = 'Isomap'\n",
    "        n_neighbors = 5\n",
    "        manifold_embed = lambda n_comp: Isomap(n_components=n_comp, n_neighbors=n_neighbors)\n",
    "        lfp_duration_s = 1 # s\n",
    "\n",
    "    if standardize:\n",
    "        signal_wake = (signal_wake - signal_wake.mean())/signal_wake.std()\n",
    "        signal_anesthesia = (signal_anesthesia - signal_anesthesia.mean())/signal_anesthesia.std()\n",
    "    \n",
    "    print(\"performing PCA...\")\n",
    "    n_components = 3\n",
    "    if shared_basis:\n",
    "        me_w = manifold_embed(n_components)\n",
    "        me_w.fit(np.vstack([signal_wake, signal_anesthesia]))\n",
    "        signal_wake_me = me_w.transform(signal_wake).cpu()\n",
    "        signal_anesthesia_me = me_w.transform(signal_anesthesia).cpu()\n",
    "        me_a = me_w\n",
    "    else:\n",
    "\n",
    "        me_w = manifold_embed(n_components)\n",
    "        signal_wake_me = me_w.fit_transform(signal_wake).cpu()\n",
    "\n",
    "        me_a = manifold_embed(n_components)\n",
    "        signal_anesthesia_me = me_a.fit_transform(signal_anesthesia).cpu()\n",
    "        \n",
    "    print(\"generating plot ...\")\n",
    "        \n",
    "    if three_dim:\n",
    "        axs = subfig.subplots(1, 2, subplot_kw=dict(projection=\"3d\"))\n",
    "    else:\n",
    "        axs = subfig.subplots(1, 2, sharex=True, sharey=True)\n",
    "\n",
    "    if scatter:\n",
    "        plot_funcs = [axs[0].scatter, axs[1].scatter]\n",
    "    else:\n",
    "        plot_funcs = [axs[0].plot, axs[1].plot]\n",
    "\n",
    "\n",
    "    if density_plot:\n",
    "        c = 'k'\n",
    "        alpha = 0.1\n",
    "        if not three_dim:\n",
    "            plot_funcs[0](signal_wake_me[start_ind:end_ind, 0], signal_wake_me[start_ind:end_ind, 1], color=c, alpha=alpha)\n",
    "            plot_funcs[1](signal_anesthesia_me[start_ind:end_ind, 0], signal_anesthesia_me[start_ind:end_ind, 1], color=c, alpha=alpha)\n",
    "        else:\n",
    "            plot_funcs[0](signal_wake_me[start_ind:end_ind, 0], signal_wake_me[start_ind:end_ind, 1], signal_wake_me[start_ind:end_ind, 2], color=c, alpha=alpha)\n",
    "            plot_funcs[1](signal_anesthesia_me[start_ind:end_ind, 0], signal_anesthesia_me[start_ind:end_ind, 1], signal_anesthesia_me[start_ind:end_ind, 2], color=c, alpha=alpha)\n",
    "    else:\n",
    "        for i in tqdm(range(start_ind, end_ind, 2)):\n",
    "            c = cmap(norm(i))\n",
    "            alpha=0.8\n",
    "            if not three_dim:\n",
    "                plot_funcs[0](signal_wake_me[i:i+2, 0], signal_wake_me[i:i+2, 1], color=c, alpha=alpha)\n",
    "                plot_funcs[1](signal_anesthesia_me[i:i+2, 0], signal_anesthesia_me[i:i+2, 1], color=c, alpha=alpha)\n",
    "            else:\n",
    "                plot_funcs[0](signal_wake_me[i:i+2, 0], signal_wake_me[i:i+2, 1], signal_wake_me[i:i+2, 2], color=c, alpha=alpha)\n",
    "                plot_funcs[1](signal_anesthesia_me[i:i+2, 0], signal_anesthesia_me[i:i+2, 1], signal_anesthesia_me[i:i+2, 2], color=c, alpha=alpha)\n",
    "    axs[0].set_title(f'Awake', fontsize=subtitle_fontsize)\n",
    "    axs[1].set_title(f'Unconscious', fontsize=subtitle_fontsize)\n",
    "    subfig.suptitle(area_labels[area], color=area_colors[area], fontsize=subsuptitle_fontsize)\n",
    "    \n",
    "    for ax in axs:\n",
    "        ax.set_xlabel('PC1', fontsize=xlabel_fontsize)\n",
    "        ax.set_ylabel('PC2', fontsize=ylabel_fontsize)\n",
    "        ax.tick_params(labelsize=tick_fontsize)\n",
    "    \n",
    "    if not three_dim:\n",
    "        for ax in axs:\n",
    "            ax.spines[['right', 'top']].set_visible(False)\n",
    "            ax.xaxis.set_ticks_position('bottom')\n",
    "            ax.tick_params(axis='y', which='both', left=True, right=False)\n",
    "    else:\n",
    "        for ax in axs:\n",
    "            ax.grid(False)\n",
    "            ax.set_ylabel('PC3', fontsize=ylabel_fontsize)\n",
    "            \n",
    "    def update_lim(lim, ax_lim):\n",
    "        if ax_lim[0] < lim[0]:\n",
    "            lim[0] = ax_lim[0]\n",
    "        if ax_lim[1] > lim[1]:\n",
    "            lim[1] = ax_lim[1]\n",
    "        \n",
    "        return lim\n",
    "    \n",
    "    if three_dim:\n",
    "        for ax in axs:\n",
    "            set_axes_equal(ax)\n",
    "        \n",
    "        xlim, ylim, zlim = [np.Inf, -np.Inf], [np.Inf, -np.Inf], [np.Inf, -np.Inf]\n",
    "        for ax in axs:\n",
    "            xlim = update_lim(xlim, ax.get_xlim())\n",
    "            ylim = update_lim(ylim, ax.get_ylim())\n",
    "            zlim = update_lim(zlim, ax.get_zlim())\n",
    "        \n",
    "        for ax in axs:\n",
    "            ax.set_xlim(xlim)\n",
    "            ax.set_ylim(ylim)\n",
    "            ax.set_zlim(zlim)\n",
    "\n",
    "    # fig.suptitle(f\"Isomap on {num_trajs} Trajector{'ies' if num_trajs > 1 else 'y'} from {area} with {n_neighbors} Neighbors and Delay Lag p={p}, PCA dim = {n_pca_components}, Subsample = {subsample}\", fontsize=19)\n",
    "    # fig.suptitle(f\"Isomap on Continuous Trajector{'ies' if num_trajs > 1 else 'y'} from {area} with {n_neighbors} Neighbors and Delay Lag p={p}, PCA dim = {n_pca_components}, Subsample = {subsample}\", fontsize=19)\n",
    "    # fig.suptitle(f\"{embed_type} on Wake Start = {start_wake:.3f} s, Anesthesia Start = {start_anesthesia:.3f} s\\n{'Not ' if not standardize else ''}Standardized, Length = {(window_lfp*dt if mode == 'lfp' else (window_rate*dt_rate)):.2f} s ({window_lfp if mode == 'lfp' else window_rate} steps), {'Shared' if shared_basis else 'Split'} Basis, indices {start_ind} - {end_ind}, Lowpass Filter = {lowpass_filter}\")\n",
    "\n",
    "    \n",
    "if not density_plot:\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "#         fig.subplots_adjust(right=0.85)\n",
    "    cbar_ax = fig.add_axes([1.05, 0.15, 0.01, 0.7])\n",
    "    # cbar = fig.colorbar(sm, cax=cbar_ax, ticks=np.arange(0, leadup + post, 250), label='Time Relative to Tone (ms)')\n",
    "    # cbar.ax.set_yticklabels(np.arange(-leadup, post, 250), fontsize=12)\n",
    "\n",
    "    cbar = fig.colorbar(sm, cax=cbar_ax, ticks=np.arange(start_ind, end_ind + 1, cbar_step), label='Time Relative to Tone (ms)')\n",
    "    cbar.ax.set_yticklabels(np.arange(start_ind, end_ind + 1, cbar_step)*dt_rate, fontsize=12)\n",
    "    cbar.set_label(label=f'Time Relative to Trajectory Start (s)', fontsize=14)\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462dea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
