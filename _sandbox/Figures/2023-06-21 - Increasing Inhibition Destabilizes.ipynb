{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sys.path.append('/om2/user/eisenaj/code/DeLASE')\n",
    "from utils import numpy_torch_conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'I' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrnn\u001b[39m(t, x, W, tau, g):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mtau)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39mx \u001b[38;5;241m+\u001b[39m g\u001b[38;5;241m*\u001b[39mW \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39mtanh(x))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;241m-\u001b[39m\u001b[43mI\u001b[49m \u001b[38;5;241m+\u001b[39m dt\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mmultiply(W_eff, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mtanh(x[t \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrnn_jacobian\u001b[39m(x, W, g, tau, dt, N, use_torch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch.DoubleTensor\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      7\u001b[0m     x \u001b[38;5;241m=\u001b[39m numpy_torch_conversion(x, use_torch, device, dtype)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'I' is not defined"
     ]
    }
   ],
   "source": [
    "def rnn(t, x, W, tau, g):\n",
    "    return (1/tau)*(-x + g*W @ np.tanh(x))\n",
    "\n",
    "-I + dt*np.multiply(W_eff, 1 - np.tanh(x[t - 1])**2)\n",
    "\n",
    "def rnn_jacobian(x, W, g, tau, dt, N, use_torch=False, device='cpu', dtype='torch.DoubleTensor'):\n",
    "    x = numpy_torch_conversion(x, use_torch, device, dtype)\n",
    "    W = numpy_torch_conversion(W, use_torch, device, dtype)\n",
    "    if use_torch:\n",
    "        I = torch.eye(N).type(dtype).to(device)\n",
    "        if len(x.shape) == 1:\n",
    "            return I + (dt/tau)*(-I + (g*W @ torch.diag(1 - torch.tanh(x)**2)))\n",
    "        else:\n",
    "            return I.unsqueeze(0) + (dt/tau)*(-I.unsqueeze(0) + (g*W*((1 - torch.tanh(x)**2).unsqueeze(1))))\n",
    "    else:\n",
    "        if len(x.shape) == 1:\n",
    "            return np.eye(N) + (dt/tau)*(-np.eye(N) + (g*W @ np.diag(1 - np.tanh(x)**2)))\n",
    "        else:\n",
    "            print((1 - np.tanh(x)**2)[:, np.newaxis].shape)\n",
    "            return np.eye(N)[np.newaxis] + (dt/tau)*(-np.eye(N)[np.newaxis] + (g*W*(1 - np.tanh(x)**2)[:, np.newaxis]))\n",
    "        \n",
    "def compute_lyaps(Js, dt=1, k=None, worker_num=None, message_queue=None, verbose=False):\n",
    "    T, n = Js.shape[0], Js.shape[1]\n",
    "    old_Q = np.eye(n)\n",
    "    if k is None:\n",
    "        k = n\n",
    "    old_Q = old_Q[:, :k]\n",
    "    lexp = np.zeros(k)\n",
    "    lexp_counts = np.zeros(k)\n",
    "    for t in tqdm(range(T), disable=not verbose):\n",
    "        # QR-decomposition of Js[t] * old_Q\n",
    "        mat_Q, mat_R = np.linalg.qr(np.dot(Js[t], old_Q))\n",
    "        # force diagonal of R to be positive\n",
    "        # (if QR = A then also QLL'R = A with L' = L^-1)\n",
    "        sign_diag = np.sign(np.diag(mat_R))\n",
    "        sign_diag[np.where(sign_diag == 0)] = 1\n",
    "        sign_diag = np.diag(sign_diag)\n",
    "#         print(sign_diag)\n",
    "        mat_Q = np.dot(mat_Q, sign_diag)\n",
    "        mat_R = np.dot(sign_diag, mat_R)\n",
    "        old_Q = mat_Q\n",
    "        # successively build sum for Lyapunov exponents\n",
    "        diag_R = np.diag(mat_R)\n",
    "\n",
    "#         print(diag_R)\n",
    "        # filter zeros in mat_R (would lead to -infs)\n",
    "        idx = np.where(diag_R > 0)\n",
    "        lexp_i = np.zeros(diag_R.shape, dtype=\"float32\")\n",
    "        lexp_i[idx] = np.log(diag_R[idx])\n",
    "#         lexp_i[np.where(diag_R == 0)] = np.inf\n",
    "        lexp[idx] += lexp_i[idx]\n",
    "        lexp_counts[idx] += 1\n",
    "\n",
    "        # it may happen that all R-matrices contained zeros => exponent really has\n",
    "        # to be -inf\n",
    "\n",
    "        # normalize exponents over number of individual mat_Rs\n",
    "#         idx = np.where(lexp_counts > 0)\n",
    "        #lexp[idx] /= lexp_counts[idx]\n",
    "#         lexp[np.where(lexp_counts == 0)] = np.inf\n",
    "\n",
    "        if message_queue is not None:\n",
    "            message_queue.put((worker_num, \"task complete\", \"DEBUG\"))\n",
    "    \n",
    "    return np.divide(lexp, lexp_counts)*(1/dt)\n",
    "\n",
    "def estimate_stability_using_particle(\n",
    "    js: np.ndarray, p: int, test_eigenvectors=False\n",
    ") -> np.ndarray:\n",
    "\n",
    "    \"\"\"Estimate maximal lyapunov exponent given a sequence of Jacobians using the technique of ___.\n",
    "    Push a random unit vector through the sequence and measure the deformation.\"\n",
    "\n",
    "    Args:\n",
    "        js (np.ndarray): Sequence of Jacobians, stored in a multi-dimensional array.\n",
    "        p (int): Number of random unit vectors to  use.\n",
    "\n",
    "    Returns:\n",
    "        lams: p-dimensional array containing estimates of maximal Lyapunov exponent.\n",
    "    \"\"\"\n",
    "\n",
    "    K, N = js.shape[0], js.shape[1]\n",
    "\n",
    "    # generate p vectors on the unit sphere in R^n\n",
    "    U = np.random.randn(N, p)\n",
    "    U /= np.linalg.norm(U, axis=0)\n",
    "\n",
    "    if test_eigenvectors:\n",
    "        # generate p vectors along the eigenvectors of js[0]\n",
    "        eig_vals, eig_vecs = np.linalg.eig(js[0])\n",
    "        # ind_max_eig = np.argmax(np.abs(eig_vals))\n",
    "        ind_max_eig = np.argmin(np.abs(eig_vals))\n",
    "        leading_eig_vec = np.real(eig_vecs[:, ind_max_eig])\n",
    "        random_scalings = np.random.normal(0, 1, p)\n",
    "        U = leading_eig_vec[:, None] * random_scalings + np.random.normal(\n",
    "            0, 0.001, (N, p)\n",
    "        )\n",
    "        U /= np.linalg.norm(U, axis=0)\n",
    "\n",
    "    # preallocate memory for lyapunov exponents\n",
    "    lams = np.zeros(p)\n",
    "\n",
    "    for k in range(K):\n",
    "\n",
    "        # push U through jacobian at time t\n",
    "        U = js[k] @ U\n",
    "\n",
    "        # measure deformation and store log\n",
    "        lams += np.log(np.linalg.norm(U, axis=0))\n",
    "\n",
    "        # renormalize U\n",
    "        U /= np.linalg.norm(U, axis=0)\n",
    "\n",
    "    # average by number time steps to get lyapunov exponent estimates\n",
    "    lams /= K\n",
    "\n",
    "    return lams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup list of gains\n",
    "# g_vals = np.linspace(0.8, 1.3, 5)\n",
    "# g_vals = [0.8, 0.9, 1, 1.1, 1.2, 1.3]\n",
    "# inhibition_scales = np.linspace(0.5, 2, 5)\n",
    "# inhibition_scales = [0.5, 0.75, 1, 1.25, 1.5, 2]\n",
    "g_vals = [0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7]\n",
    "inhibition_scales = [0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508ed0d1d76d4039ad4cd4bfb1a471b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Simulate the stochastic differential equation\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, T):\n\u001b[0;32m---> 31\u001b[0m     x[i] \u001b[38;5;241m=\u001b[39m x[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m dt \u001b[38;5;241m+\u001b[39m g_dW(x[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m) \u001b[38;5;241m*\u001b[39m dW[i]\n\u001b[1;32m     33\u001b[0m signals[(g, inh_scale)] \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     35\u001b[0m iterator\u001b[38;5;241m.\u001b[39mupdate()\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mrnn\u001b[0;34m(t, x, W, tau, g)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrnn\u001b[39m(t, x, W, tau, g):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mtau)\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39mx \u001b[38;5;241m+\u001b[39m \u001b[43mg\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mW\u001b[49m \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39mtanh(x))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# simulate a bunch of networks with scale inhibition\n",
    "N = 512\n",
    "T = 10000\n",
    "dt = 0.01\n",
    "tau = 1\n",
    "def g_dW(x, scale=1):\n",
    "    return scale\n",
    "W = np.random.randn(N, N)*(1/np.sqrt(N))\n",
    "\n",
    "signals = {}\n",
    "\n",
    "iterator = tqdm(total=len(g_vals)*len(inhibition_scales))\n",
    "for g in g_vals:\n",
    "    for inh_scale in inhibition_scales:\n",
    "        \n",
    "        W_new = deepcopy(W)\n",
    "        W_new *= g\n",
    "        W_new[W_new < 0] *= inh_scale\n",
    "        \n",
    "        dW = np.sqrt(dt) * np.random.randn(T,N)\n",
    "        x0 = np.random.randn(N)\n",
    "        # Define the function g(x)\n",
    "\n",
    "\n",
    "        # Initialize the x array\n",
    "        x = np.zeros((T, N))\n",
    "        x[0] = np.random.randn(N)\n",
    "\n",
    "        # Simulate the stochastic differential equation\n",
    "        for i in range(1, T):\n",
    "            x[i] = x[i-1] + rnn((i - 1)*dt, x[i-1], W_new, tau, 1) * dt + g_dW(x[i-1], scale=0.05) * dW[i]\n",
    "\n",
    "        signals[(g, inh_scale)] = x\n",
    "\n",
    "        iterator.update()\n",
    "iterator.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_torch = True\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "num_batches = int(T/batch_size)\n",
    "iterator = tqdm(total=len(signals)*num_batches)\n",
    "lyaps = {}\n",
    "for key, signal in signals.items():\n",
    "    signal = signal[2000:]\n",
    "    Js = np.zeros((signal.shape[0], N, N))\n",
    "    g, inh_scale = key\n",
    "    W_new = deepcopy(W)\n",
    "    W_new *= g\n",
    "    W_new[W_new < 0] *= inh_scale\n",
    "#     print(\"Computing Jacobians..\")\n",
    "    for batch_num in range(num_batches):\n",
    "        start_ind = batch_num*batch_size\n",
    "        end_ind = np.min([(batch_num + 1)*batch_size, signal.shape[0]])\n",
    "        batch_Js = rnn_jacobian(signal[start_ind:end_ind], W_new, 1, tau, dt, N, use_torch=use_torch, device=device)\n",
    "        if device == 'cuda':\n",
    "            batch_Js = batch_Js.cpu()\n",
    "        Js[start_ind:end_ind] = batch_Js\n",
    "        \n",
    "        iterator.update()\n",
    "\n",
    "#     print(\"Computing Lyaps...\")\n",
    "    lyaps[key] = compute_lyaps(Js, dt=dt, k=3, verbose=False)\n",
    "#     lyaps[key] = estimate_stability_using_particle(Js, p=50)/dt\n",
    "iterator.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyap_matrix = np.zeros((len(g_vals), len(inhibition_scales)))\n",
    "\n",
    "for i, g in enumerate(g_vals):\n",
    "    for j, inh in enumerate(inhibition_scales):\n",
    "        lyap_matrix[i][j] = lyaps[(g, inh)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(g_vals)):\n",
    "    plt.plot(inhibition_scales, lyap_matrix[i], label=f\"g = {g_vals[i]}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(lyap_matrix)\n",
    "plt.xticks(np.arange(len(inhibition_scales)), inhibition_scales)\n",
    "plt.yticks(np.arange(len(g_vals)), g_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
